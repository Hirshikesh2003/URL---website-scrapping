# URL---website-scrapping 

The basic idea of this project is webscraping with python, the whole project is developed in juoyter notebook.

Packages used - Beautiful Soup, it is python package for parsing HTMl and XML documents, it creates a parse tree for parsed pages that can be used to extract data from HTML, which is used for web scraping.

Pandas is also used, alongside with requests.

Just copy paste the URL of the website that we want to scrape, beautiful soup along with requests will allow us to read the content of the website and that content can be saved in a text document for furthur analysis.

From the code we can see the content in output, (PS: It is long, use the scroll bar)

There's a part 2 for this project as we are only scraping the website, we can use that content for some analysis, that part wll be covered in the repo - "Word analysis using NLTK" check that out too..

For a headsup, I have covered some part in this repo itself, now we will be using the most useful NLTKpackage, stopwords and corpus.

Upload the scraped document of the URL to the code so that we can use the stop words to remove the unwanted words and keep the important ones for the analysis, later we use word tokenizer to make our work simple.

In the end the whole content of the URL is saved in your text docments as single - important words
